#! /usr/bin/env python3

"""
 affinity_graph.py - offers a mechanism for producing an affinity graph as follows:
   - create a random bipartite graph G_B = (V_0, V_1, A)
   - for each v,w in V_0, add edge vw if there exists x in V_1 such that vx,wx in A
   - remove V_1

 @author Matthias Stallmann
 @date 2018/3/29
"""

import sys
import os
import random
import argparse

DEBUG = False

def parse_arguments():
    parser = argparse.ArgumentParser(description="Creates an affinity graph from a random"
                                     + " bipartite graph."
                                     + " Two vertices v,w are adjacent if they"
                                     + " share a neighbor on the other side of the biparition")
    parser.add_argument("-n", "--vertices", help="desired number of vertices")
    parser.add_argument("-p", "--edges", help="desired number of edges (result may differ)")
    parser.add_argument("-d", "--deg_var", help="degree variance for the graph"
                        + ", derived from the bipartite graph;"
                        + " -d D implies geometrically scaled range"
                        + " [x * (1/2^D), min(x * (2^D), 1)], where x is the edge probability.")
    parser.add_argument("-s", "--seed", help="random seed (0 if missing, i.e., use internal mechanism)")
    parser.add_argument("-o", "--prefix", help="prefix for an output file name, use stdout if missing")
    args = parser.parse_args()
    return args

def date():
    date_pipe = os.popen( 'date -u "+%Y/%m/%d %H:%M"' )
    return date_pipe.readlines()[0].split()[0]

# for debugging
def debug_print( format_string, tuple_of_values ):
    if DEBUG:
        print(format_string % tuple_of_values)

# prints the name and value of a variable, separated by a space to the file
# stream
def printvar( file_stream, var_name ):
    file_stream.write( var_name )
    file_stream.write( " " )
    file_stream.write( str(eval( var_name )) )
    file_stream.write( "\n" )

# returns true with probability p; if p < 0, returns false, if p > 1, returns
# true
def true_with_probability( p ):
    random_real = random.random() # in the interval [0,1)
    if random_real < p:
        return True
        return False

# returns the list L with all occurrences of x removed
def removed_from( x, L ):
    return [y for y in L if y != x]

# returns the median of L, a list of numbers, assumes L non-empty 
def median(L):
    sorted_version = sorted(L)
    length = len(sorted_version)
    if length % 2 == 1:
        # odd length
        return sorted_version[ (length - 1) / 2 ]
    else:
        # even length
        return (sorted_version[ length / 2 - 1 ] + sorted_version[ length / 2]) / 2.0

# L is a list of numbers
#
# returns a tuple of the form (min, min_at, max, max_at, mean, median), where
# min, max, mean, and median are the usual statistics; min_at and max_at are
# lists of indices where the minimum and maximum occur
# Assumes L is not empty
def list_statistics( L ):
    minimum = min(L)
    min_at = [i for i, x in enumerate(L) if x == minimum] 
    maximum = max(L)
    max_at = [i for i, x in enumerate(L) if x == maximum]
    mean = sum(L) / float(len(L))
    med = median(L)
    return (minimum, min_at, maximum, max_at, mean, med)

# returns a string of the form XpY from the floating point number z = X.Y...
def convert_float_to_string( z ):
    X = int( z )
    Y = int( (z - X) * 10 )
    return "%dp%d" % (X, Y)

# returns a string of the form PREFIX_VERTICES_EDGES_VARIANCE_SEED
# to be used as a file name. Floating point numbers are of the form XpY,
# where X is the digit preceding the decimal point and Y is the first digit
# after it.
def create_name( prefix, vertices, edges, variance, seed ):
    variance_string = convert_float_to_string( variance )
    return "%s_%04d_%04d_%s_%d" % (prefix, vertices, edges, variance_string, seed)

# prints the graph in snap format into the file stream.
def print_graph( file_stream, vertices, edges, variance, seed ):
    file_stream.write( "# generated by affinity_graph.py on %s\n" % date() )
    file_stream.write( "# vertices edges degree_variance seed\n" )
    file_stream.write( "# %d %d %4.2f %d\n" % (vertices, edges, degree_variance, seed) )
    print_edges( file_stream )
    # print "adj_in =", adj_in
    # print "adj_out =", adj_out

def print_nodes( file_stream ):
    global layer
    for k in range(_layers):
        this_layer = layer[k]
        position = 0
        for i in range(len(this_layer)):
            node = this_layer[i]
            file_stream.write( "n %d %d %d\n" % (node, k, position) )
            position = position + 1

def print_edges( file_stream ):
    global adj_out
    for source in range(_nodes):
        outgoing_neighbors = adj_out[source]
        for target_index in range(len(outgoing_neighbors)): 
            file_stream.write( "e %d %d\n" % (source, outgoing_neighbors[target_index]) )

# returns the number of edges between layers k and k+1 divided by the number
# of potential edges; node_list = the list of nodes on layer k
def channel_density( node_list ):
    global adj_out
    global my_layer
    number_of_edges = sum( map( outdegree, node_list ) )
    # print "channel density, num_edges =", number_of_edges, ", node_list =", node_list
    # use the first node of the layer as an arbitrary node to get layer number
    k = my_layer[ node_list[0] ]
    potential_edges = len( layer[k] ) * len( layer[k+1] )
    return number_of_edges / float( potential_edges )

# expression is some expression involving a node, e.g., "len(adj_in[ node ])"
# to get stats on the indegree for nodes, the list of nodes on the layer
def layer_stats( expression, node_list ):
    data_list = [eval( expression ) for node in node_list]
    return list_statistics( data_list )

# degree discrepancy in a channel is max_degree / median_degree
# all the 0's are filtered out first to ensure that the discrepancy makes sense
# if the resulting list is empty, a -1 is reported
def degree_discrepancy( node_list ):
    k = my_layer[ node_list[0] ]
    out_degrees = list(map( outdegree, node_list ))
    in_degrees = list(map( indegree, layer[k+1] ))
    degree_list = out_degrees + in_degrees
    degree_list = [x for x in degree_list if x != 0]
    # print "degree_discrepancy, k =", k, ", degree_list =", degree_list
    if degree_list == 0:
        return -1
    median_degree = median( degree_list )
    return max( degree_list ) / float( median_degree )

# returns the maximum indegree among nodes on the list
def get_max_indegree( node_list ):
    indegrees = list(map( indegree, node_list ))
    return max( indegrees )

# returns the maximum outdegree among nodes on the list
def get_max_outdegree( node_list ):
    outdegrees = list(map( outdegree, node_list ))
    return max( outdegrees )

# returns the maximum total degree among nodes on the list
def get_max_degree( node_list ):
    degrees = list(map( degree, node_list ))
    return max( degrees )

def indegree_zero_nodes( node_list ):
    return len( [node for node in node_list if indegree( node ) == 0] )

def outdegree_zero_nodes( node_list ):
    return len( [node for node in node_list if outdegree( node ) == 0] )

def channel_edge_count( node_list ):
    return sum( map( outdegree, node_list ) )

# prints a varety of statistics about layers and degrees to the file_stream
def print_all_stats( file_stream ):
    print_statistics( file_stream, "layer_width", list(map( len, layer )) )
    file_stream.write( "channel_edge_counts = %s\n" % (list(map( channel_edge_count, layer[0:_layers-1])) ) )
    print_statistics( file_stream, "channel_density", list(map( channel_density, layer[0:_layers-1] )) )
    print_statistics( file_stream, "indeg_0_nodes", list(map( indegree_zero_nodes, layer[1:_layers] )) )
    print_statistics( file_stream, "outdeg_0_nodes", list(map( outdegree_zero_nodes, layer[0:_layers-1] )) )
    print_statistics( file_stream, "max_in_degree", list(map( get_max_indegree, layer[1:_layers] )) )
    print_statistics( file_stream, "max_out_degree", list(map( get_max_outdegree, layer[0:_layers-1])) )
    print_statistics( file_stream, "max_degree", list(map( get_max_degree, layer )) )
    print_statistics( file_stream, "degree_discrepancy", [degree_discrepancy( node_list ) for node_list in layer[0:_layers-1]] ) 

def initialize_globals():
    global layer
    global my_layer
    global adj_in
    global adj_out
    layer = [[]] * _layers
    my_layer = [-1] * _nodes
    # the following need to be created more carefully; the lists will get
    # appended to later
    adj_in = []
    adj_out = []
    for v in range(_nodes):
        adj_in.append([])
        adj_out.append([])

def create_layers( width_var ):
    global layer
    global my_layer
    avg_nodes_per_layer = _nodes / float(_layers)
    width_deviance = avg_nodes_per_layer * width_var
    nodes_added_so_far = 0
    nodes_remaining = _nodes
    layers_remaining = _layers
    for k in range(_layers-1):
        average_remaining_width = nodes_remaining / float( layers_remaining )
        # print "k =", k
        # print "layers_remaining =", layers_remaining
        # print "nodes remaining =", nodes_remaining
        # print "nodes_added_so_far =", nodes_added_so_far
        # print "average_remaining_width =", average_remaining_width
        layer_size = random.randrange( int(average_remaining_width - width_deviance), int(average_remaining_width + width_deviance + 1 ) )

        # ensure that (i) every layer has at least three nodes; and (ii) all
        # subsequent layers can have at least four nodes (to allow some
        # variance if desired)
        if layer_size < 3: layer_size = 3
        if nodes_remaining - layer_size < 4 * (_layers - 1 - k):
            layer_size = nodes_remaining - 4 * (_layers - 1 - k)
        # ensure that remaining layers are no wider than
        # average_remaining_width + width_deviance, i.e., make this layer
        # larger if necessary so that subsequent layers don't get too large
        if (nodes_remaining - layer_size) / float(layers_remaining - 1)  > average_remaining_width + width_deviance:
            layer_size = int( average_remaining_width + width_deviance )

        # print "layer", k, "has", layer_size, "nodes, ", nodes_added_so_far, "nodes have been added"

        add_nodes_to_layer( k, nodes_added_so_far, layer_size )
        nodes_added_so_far = nodes_added_so_far + layer_size
        nodes_remaining = nodes_remaining - layer_size
        layers_remaining = layers_remaining - 1

    # print "layer", layers - 1, "has", nodes_remaining, "nodes"
    add_nodes_to_layer( _layers - 1, nodes_added_so_far, nodes_remaining )

def add_node_to_layer( node, k ):
    my_layer[ node ] = k

# determines which nodes are on layer k and records the appropriate
# information
def add_nodes_to_layer( k, nodes_added_so_far, layer_size ):
    global layer
    global my_layer
    # print "add_nodes_to_layer, k =", k, ", added_so_far =", nodes_added_so_far, ", layer_size =", layer_size
    layer[k] = list(range(nodes_added_so_far, nodes_added_so_far + layer_size))
    debug_print( "layer %d is %s", ( k, layer[k] ) )
    list(map( lambda node: add_node_to_layer( node, k), layer[k] ))
    #   print "my_layer =", my_layer
    #   print "layer =", layer

def indegree( node ):
    global adj_in
    return len( adj_in[node] )

def outdegree( node ):
    global adj_out
    return len( adj_out[node] )

def degree( node ):
    return indegree( node ) + outdegree( node )

def get_incoming_layer( k ):
    if k == 0:
        return []
    return layer[ k - 1 ]

def get_outgoing_layer( k ):
    if k == _layers - 1:
        return []
    return layer[ k + 1 ]

def nodes_needing_in_edges():
    global my_layer
    global adj_in
    return [node for node in range( _nodes ) if my_layer[node] != 0 and adj_in[node] == []]

def nodes_needing_out_edges():
    global my_layer
    global adj_out
    return [node for node in range( _nodes ) if my_layer[node] != _layers - 1 and adj_out[node] == []]

def isolated_nodes():
    return [node for node in range( _nodes ) if degree( node ) == 0];

# returns true if the node is *not* already adjacent to all nodes on the
# preceding and following layers
def is_available( node ):
    return len( adj_in[node] ) + len( adj_out[node] ) < len( get_incoming_layer( my_layer[node] ) ) + len( get_outgoing_layer( my_layer[node] ) )

# repeatedly picks a node not in the current tree and attaches it to a tree
# node; the frontier is the set of nodes that are on layers adjacent to
# layers of tree nodes; the set of tree nodes is maintained by the buckets (a
# node not in the tree is not in any bucket
def add_tree_edges( degree_var ):
    global _nodes
    # first create an initial edge between a node on layer 0 and a node on
    # layer 1
    start_node = random.choice( layer[0] )
    next_node = random.choice( layer[1] )
    init_buckets( [ start_node, next_node ] )
    add_edge( start_node, next_node )
    if _layers > 2:
        frontier_layer = 2
        frontier = layer[0] + layer[1] + layer[2]
    else:
        frontier_layer = 1
        frontier = layer[0] + layer[1]
    frontier = removed_from( start_node, frontier )
    frontier = removed_from( next_node, frontier )
    for i in range( _nodes - 2 ):
        if DEBUG:
            print("adding tree edges: i =", i, ", frontier =", frontier)
        frontier_node = random.choice( frontier )
        frontier = removed_from( frontier_node, frontier )
        tree_node_choices = get_adjacent_node_choices( frontier_node, degree_var )
        tree_node = random.choice( tree_node_choices )
        add_edge( frontier_node, tree_node )
        if my_layer[ frontier_node ] >= frontier_layer and frontier_layer < _layers - 1:
            frontier_layer = frontier_layer + 1
            frontier = frontier + layer[ frontier_layer ]

def add_other_edges( degree_var ):
    # init_buckets( range( nodes ) )
    # init_sets( nodes )

    for i in range( _edges - _nodes + 1 ): 
        # print "adding_edges: i =", i
        # print "need_in =", need_in
        # print "need_out =", need_out 
        # print "lengths =", len( need_in ) + len( need_out )
        # need_in = nodes_needing_in_edges()
        # need_out = nodes_needing_out_edges()
        # print "adding_edges: i =", i
        # print "need_in =", need_in
        # print "need_out =", need_out 
        # print "lengths =", len( need_in ) + len( need_out )
        # if len( need_in ) + len( need_out ) >= edges - i:
            # ensure that all nodes on interior layers have indegree > 0
            # and outdegree > 0 and that nodes on outer layers are not
            # isolated
        #     v = random.choice( get_nodes_in_smallest_components() )
        # else:
        choices = get_node_choices( degree_var )
        if choices == []:
            return
        v = random.choice( choices )
        adjacent_node_choices = get_adjacent_node_choices( v, degree_var )
        if DEBUG:
            print("adding edges: v =", v, "adjacent choices =", adjacent_node_choices)
        # filtered = filter_for_connectivity( v, adjacent_node_choices )
        # if filtered != []:
        #     adjacent_node_choices = filtered
        # print "post-filter: v =", v, "adjacent choices =", adjacent_node_choices
        w = random.choice( adjacent_node_choices )
        #        print "remaining edges =", edges - i
        #        print "chosen node =", v, ", neighbor =", w
        add_edge( v, w )
        # union( v, w )
        #        print "adj_out[%d] =" % (v), adj_out[v]
        #        print "adj_in[%d] = " % (w), adj_in[w]

def filter_for_connectivity( v, choices ):
    return [w for w in choices if find( w ) != find( v )]

def add_edge( v, w ):
    global adj_in
    global adj_out
    if DEBUG:
        print("add_edge", v, w)

    # the following code is designed to keep the degree of nodes on small
    # layers from getting too large; if layer widths differ a lot, a small
    # layer between two larger ones will have every node connected to every
    # node on the larger layers.
    # layer_width_v = len( layer[ my_layer[v] ] )
    # layer_width_w = len( layer[ my_layer[w] ] )
    # if layer_width_v > layer_width_w:
    #     if true_with_probability( layer_width_v / float( layer_width_w ) - 1 ):
    #         increment_degree(v)
    #         increment_degree(w)

    if my_layer[v] > my_layer[w]:
        temp = v
        v = w
        w = temp
    # at this point vw is directed from lower numbered to higher numbered layer
    adj_in[w].append(v)
    adj_out[v].append(w)
    increment_degree(v)
    increment_degree(w)
    # without the following adjustment, nodes on the first and last layer end
    # up with too many edges (their degree never gets incremented for
    # incoming or outgoing edges, respectively)
    if my_layer[v] == 0:
        increment_degree(v)
    if my_layer[w] == _layers - 1:
        increment_degree(w)

# The degree bucket data structure is the key to controlling degree
# distributions. Here, bucket[k] stores nodes whose total degree is k and
# my_bucket[node] stores the index of the bucket containing the node or -1 if
# it is no longer available for having edges added to it; my_bucket is
# initially 0 even if the node is not in a bucket yet.
#
# When degree variance is small, nodes in buckets with small indices are
# given preference. If degree variance is 1.0 all nodes are treated
# equally. If it's greater than 1, the probability of a node from bucket[k]
# being chosen is 2^k/2^m, where m is the maximum index + 1.
#
# @todo Obviously this should be a class, but the current implementation is
# meant to be quick and dirty

def init_buckets( node_list ):
    global bucket
    global my_bucket
    global lowest_bucket_index
    global highest_bucket_index
    bucket = [ node_list ]
    my_bucket = [0] * _nodes
    highest_bucket_index = 0
    #    print "bucket =", bucket
    #    print "my_bucket =", my_bucket

# moves the node into the next higher bucket
def increment_degree( node ):
    global bucket
    global my_bucket
    global highest_bucket_index
    k = my_bucket[node]
    bucket[k] = removed_from( node, bucket[k] )
    if highest_bucket_index == k:
        bucket.append( [] )
        highest_bucket_index = highest_bucket_index + 1
    bucket[k+1].append( node )
    my_bucket[node] = k + 1

    # print "bucket =", bucket
    # print "my_bucket[%d] =" % (node), my_bucket[node]
    # print "lowest_bucket_index = ", lowest_bucket_index
    # print "highest_bucket_index =", highest_bucket_index

# returns all the available nodes on the list: those not yet
# adjacent to all nodes on the layer above and the layer below.
def get_available_nodes( node_list ):
    return [node for node in node_list if is_available( node )]

# returns a random bucket from a (filtered) list of buckets; the bucket
# chosen is based on a mapping from the unit interval to the range of indices
# of buckets_to_choose_from
def choose_random_bucket( buckets_to_choose_from, degree_var ):
    if buckets_to_choose_from == []:
        return []
    uniform_number = random.random()
    choice_index = int( uniform_number * degree_var * len( buckets_to_choose_from ) + 0.5 )
    if choice_index >= len( buckets_to_choose_from ):
        choice_index = len( buckets_to_choose_from ) - 1
    return buckets_to_choose_from[ choice_index ]
    
# returns a random bucket from those that contain available nodes
# determined by degree variance
def get_node_choices( degree_var ):
    # print "get_node_choices, bucket =", bucket
    buckets_to_choose_from = list(map( get_available_nodes, bucket ))
    buckets_to_choose_from = [node_list for node_list in buckets_to_choose_from if node_list != []]
    # print "get_node_choices: buckets_to_choose_from =", buckets_to_choose_from
    return choose_random_bucket( buckets_to_choose_from, degree_var )

# returns node choices based on degree variance and several constraints:
# - if
# v has no incoming edges it must be connected to a node on the previous
# layer - nodes must be available - nodes must be chosen from a non-empty
# bucket, depending on degree variance
def get_adjacent_node_choices( v, degree_var ):
    if DEBUG:
        print("-> get_adjacent_node_choices, v =", v, ", degree_var =", degree_var)
    if my_layer[v] > 0 and adj_in[v] == [] and adj_out[v] != []:
        choices = get_incoming_layer( my_layer[v] )
        desperate = [node for node in choices if adj_out[node] == 0]
    elif my_layer[v] < _layers - 1 and adj_out[v] == [] and adj_in[v] != []:
        choices = get_outgoing_layer( my_layer[v] )
        desperate = [node for node in choices if adj_in[node] == 0]
    else:
        in_choices = list( set( get_incoming_layer( my_layer[v] ) ) - set( adj_in[v] ) )
        desperate = [node for node in in_choices if adj_out[node] == 0]
        out_choices = list( set( get_outgoing_layer( my_layer[v] ) ) - set( adj_out[v] ) )
        desperate = desperate + [node for node in out_choices if adj_in[node] == 0]
        choices = in_choices + out_choices

        if DEBUG:
            print("  get_adjacent_node_choices: choices =", choices)
            print("                             desperate =", desperate)
    if desperate != []:
        return desperate

    buckets_to_choose_from = [list( set( node_list ) & set( choices ) ) for node_list in bucket]
    buckets_to_choose_from = [node_list for node_list in buckets_to_choose_from if node_list != []]
    if DEBUG:
        print("  get_adjacent_node_choices: buckets_to_choose_from =", buckets_to_choose_from)
    # at this point, buckets is a list of non-empty buckets each of which
    # consists entirely of potential neighbors of v
    return choose_random_bucket( buckets_to_choose_from, degree_var)


# disjoint set union (without union by rank)
# size_list[i] = list of nodes whose component size is i 
def init_sets( _nodes ):
    global parent
    global my_component_size
    global size_list
    global smallest_component_size
    parent = list(range( _nodes))
    my_component_size = [ 1 ] * _nodes
    smallest_component_size = 1
    size_list = []
    for v in range(_nodes):
        size_list.append([])
    size_list[ 1 ] = list(range( _nodes))

def find( x ):
    global parent
    if x == parent[x]:
        return x
    root = find( parent[x] )
    parent[x] = root
    return root

def link( x, y ):
    global parent
    parent[x] = y

def union( x, y ):
    global my_component_size
    global size_list
    global smallest_component_size
    link( find( x ), find( y ) )
    size_x = my_component_size[ x ]
    size_y = my_component_size[ y ]
    total_size = size_x + size_y
    size_list[ size_x ] = list( set( size_list[ size_x ] ) - set( [ x ] ) )
    size_list[ size_y ] = list( set( size_list[ size_y ] ) - set( [ y ] ) )
    my_component_size[ x ] = total_size
    my_component_size[ y ] = total_size
    size_list[ total_size ].append( x )
    size_list[ total_size ].append( y )
    while size_list[ smallest_component_size ] == []:
        smallest_component_size = smallest_component_size + 1
        
def get_nodes_in_smallest_components():
    return size_list[ smallest_component_size ]

# the following are global arrays (lists)
#    layer[i] is the list of (indices of) nodes on layer i
#    my_layer[i] is the layer that contains node i
#    adj_in[i], where my_layer[i] = k,
#               is the list of nodes on layer k-1 that are adjacent to i
#    potential_in[i] is the list of nodes on layer k-1 not adjacent to i 
#    adj_out[i] where my_layer[i] = k,
#               is the list of nodes on layer k+1 that are adjacent to i
#    potential_out[i] is the list of nodes on layer k+1 not adjacent to i 

if __name__ == "__main__":
    global _nodes
    global _edges
    global _layers
    args = parse_arguments()
    sys.exit()

    if seed > 0:
        random.seed( seed )
    initialize_globals()
    create_bipartite_vertices( args.vertices, args.width )
    create_bipartite_edges( args.edge_prob, args.deg_var )
    print_graph( sys.stdout, args )

#  [Last modified: 2019 09 17 at 21:56:46 GMT]
